# Model configuration
model:
  embedding_model: "models/embedding-001"
  llm_model: "gemini-1.5-flash"

# Processing configuration
processing:
  chunk_size: 400  # tokens
  chunk_overlap: 50  # tokens
  max_candidates: 5
  vector_search_k: 20
  max_chunks_per_candidate: 20

# Database configuration
database:
  collection_name: "resume_langchain"
  
# UI configuration
ui:
  max_file_size_mb: 10
  allowed_file_types: ["pdf", "docx", "txt"]
  default_top_k: 3